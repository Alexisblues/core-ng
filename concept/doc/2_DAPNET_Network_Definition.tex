\chapter{DAPNET Network Definition}


\section{Cluster Description}

\subsection{Real-time Message delivery with RabbitMQ}
\label{dapnetdef:clusterdesc:rabbitmq}

\subsection{Distributed Database with CouchDB}
\label{dapnetdef:clusterdesc:couchdb}

\subsection{Authentication Concept}

\subsection{Integration of new Nodes}


\section{Interface Overview and Purpose}

\subsection{RabbitMQ Exchange}
There are 3 exchanges on each RabbitMQ instance available:
\begin{enumerate}
\item dapnet.calls: Messages coming from other nodes but not from the node where the instance is running
\item dapnet.local\_calls: Messages coming from the local node instance
\item dapnet.telemetry: Messages containing telemetry from transmitters
\end{enumerate}

Transmitters publish to the \textbf{dapnet.telemetry} their telemetry data, while consume from the \textbf{dapnet.calls} and \textbf{dapnet.local\_calls} the data to be transmitted.

\textbf{dapnet.calls}\\
This exchange received from all Core instance, \textit{but not the local one} the data to be transmitted by the transmitter software. The idea is to distinguish between \textit{local} data coming from the local Core instance and data coming from the DAPNET network. This is necessary, as for example the calls to set the time on the pagers are generated by the local Core and not shall not distributed to other Cores and their connected transmitter to avoid duplicates.
Personal calls are always emitted in this exchange, as they are unique and only emitted by the Core that receives the call via the \hyperref[dapnetdef:corerestapi]{Core REST API}.
Rubric content is also emitted here.\\
Via the routing key, the transmitter to receive the call is defined. 

\textbf{dapnet.local\_calls}\\
As described in the paragraph before, the local Core emits to this exchange special calls like the time set calls and the rubric names and repetitions of rubric for the local connected transmitters.
In short, all calls that are generated by the \hyperref[dapnetdef:other:scheduler]{Scheduler} in a Core instance are emitted to this exchange. As the scheduler run on every node, otherwise the calls would be transmitted several times by the same transmitter.
This exchange is not distributed to other RabbitMQ instances on other Cores.
\todo{DL2IC: Please confirm}

\textbf{dapnet.telemetry}\\
On each Core instance, the \hyperref[dapnetdef:statisticstatustelemetry]{Statistic, Status and Telemetry} microservice described in section \ref{dapnetdef:statisticstatustelemetry} is consuming the telemetry of all transmitters. The received data is stored and delivered via the \hyperref[dapnetdef:websocket]{Websocket API} in section \ref{dapnetdef:websocket} to connected websites or apps.

\subsection{CouchDB Interface}
\label{dapnetdef:couchdbinterface}
The CouchDB interface is a REST interface defined in the CouchDB documentation. All communication with the CouchDB database are done by means of the interface. No user should be able to connect to the CouchDB REST interface, only the Core software components should be able to do so.
\todo{DL2IC: Please confirm, what about Auth towards the CouchDB from the Core side?} Localhost connections w/o Auth?

\subsection{Core REST API}
\label{dapnetdef:corerestapi}
The Core REST API is the main interface for user interactions with the DAPNET network.

\subsection{Statistic, Status and Telemetry REST API}
\label{dapnetdef:statisticstatustelemetry}


\subsection{Websocket for real-time updates on configuration, Statistics and Telemetry API}
\label{dapnetdef:websocket}

\subsection{MQTT Fanout for third-party consumers}
\label{dapnetdef:mqttfanout}
In order to allow third-party application to consume the data sent out by DAPNET transmitters in an easy and most generic way, there is an MQTT brocker on each Core. As the \hyperref[dapnetdef:clusterdesc:rabbitmq]{RabbitMQ} instance already has a plugin to act as ans MQTT broker, this solution is chosen.\\
To manage dynamically the third-party applications attached to DAPNET, there is a \hyperref[dapnetdef:clusterdesc:couchdb]{CouchDB}-Database containing the existing third-party descriptive names, corresponding MQTT topic names and authentication credentials to be allowed to subscribe to the that specific MQTT topic.\\
It's a intention to not fan out every content on DAPNET to every third-party application but let the user decide if personal calls directed to her/him will be available on other third-party applications or not. The website will display opt-in checkboxes for each subscriber to enable or disable the message delivery for each third-party application. As we have had some issues in this topic in the past, this seems the best but still generic and dynamic solution.\\
The fan out consists of the source and destination callsign, the destination RIC and SubRIC and an array of callsign and geographic location of the transmitters, where this specific call is supposed to be sent out by DAPNET transmitters. The type of transmitter is also given. The reason to output also the transmitter and their location is to enable third-party applications to estimate the content's distribution geographic area and take adequate action for their own delivery or further processing. (Example: Regional Rubric content to Regional DMR Group SMS.)\\
The third-party applications can (if access is granted) only read from the topic. All Core instaces have read/write access to publish the data.\\
The MQTT topics are kept local on the Core instance and are never distributed between DAPNET-Cores.
\todo{DL2IC: Please confirm}

\section{Other Definitions}

\subsection{Scheduler}
\label{dapnetdef:other:scheduler}

\subsection{User Roles and Permissions}
There are two types of users: Admins and Non-Admins. Admins are allowed to do everything. Non-Admins are just allowed to edit the entities that they own and send calls.
\todo{Make overview of data displayed to Non-Admin users from CouchDB in REST-Calls (see \ref{protocoldef:corerestapi} and Websocket \ref{protocoldef:websocketapi}.}